{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We are going to train a convolutional neural network (cnn) to recognize facial emotions. Then we use the output of the emotions to play a game in a browser which is like guitarhero. Instead of pressing the matching button at the right time, you can use your face and make the same emotion as needed. Our program then checks wheter you did a good job (same emotion) or if you weren't that clear with your facial emotion!\n",
    "\n",
    "\n",
    "## Dataset\n",
    "\n",
    "As a dataset, we use videos from 23 different actors who sing and say a sentence in eight different emotions. \n",
    "Our old approach was the following: We will seperate the videos into each emotion and then take several screenshots from the video.\n",
    "Our new approach is to use a face landmark recognition api too feed our model with our data to train it on different emotions.\n",
    "\n",
    "\n",
    "## Credits\n",
    "\n",
    "\n",
    "Credits:\n",
    "\"[The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)](https://zenodo.org/record/1188976)\" by Livingstone & Russo is licensed under [CC BY-NA-SC 4.0.](https://creativecommons.org/licenses/by-nc-sa/4.0/)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "First of all we inport os, shutil and glob. glob is used to match path names.\n",
    "We are going to copy every video into one folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emotion,pixels,Usage\\n'\n",
      " '0,70 80 82 72 58 58 60 63 54 58 60 48 89 115 121 119 115 110 98 91 84 84 90 99 110 126 143 153 158 171 169 172 169 165 129 110 113 107 95 79 66 62 56 57 61 52 43 41 65 61 58 57 56 69 75 70 65 56 54 105 146 154 151 151 155 155 150 147 147 148 152 158 164 172 177 182 186 189 188 190 188 180 167 116 95 103 97 77 72 62 55 58 54 56 52 44 50 43 54 64 63 71 68 64 52 66 119 156 161 164 163 164 167 168 170 174 175 176 178 179 183 187 190 195 197 198 197 198 195 191 190 145 86 100 90 65 57 60 54 51 41 49 56 47 38 44 63 55 46 52 54 55 83 138 157 158 165 168 172 171 173 176 179 179 180 182 185 187 189 189 192 197 200 199 196 198 200 198 197 177 91 87 96 58 58 59 51 42 37 41 47 45 37 35 36 30 41 47 59 94 141 159 161 161 164 170 171 172 176 178 179 182 183 183 187 189 192 192 194 195 200 200 199 199 200 201 197 193 111 71 108 69 55 61 51 42 43 56 54 44 24 29 31 45 61 72 100 136 150 159 163 162 163 170 172 171 174 177 177 180 187 186 187 189 192 192 194 195 196 197 199 200 201 200 197 201 137 58 98 92 57 62 53 47 41 40 51 43 24 35 52 63 75 104 129 143 149 158 162 164 166 171 173 172 174 178 178 179 187 188 188 191 193 194 195 198 199 199 197 198 197 197 197 201 164 52 78 87 69 58 56 50 54 39 44 42 26 31 49 65 91 119 134 145 147 152 159 163 167 171 170 169 174 178 178 179 187 187 185 187 190 188 187 191 197 201 199 199 200 197 196 197 182 58 62 77 61 60 55 49 59 52 54 44 22 30 47 68 102 123 136 144 148 150 153 157 167 172 173 170 171 177 179 178 186 190 186 189 196 193 191 194 190 190 192 197 201 203 199 194 189 69 48 74 56 60 57 50 59 59 51 41 20 34 47 79 111 132 139 143 145 147 150 151 160 169 172 171 167 171 177 177 174 180 182 181 192 196 189 192 198 195 194 196 198 201 202 195 189 70 39 69 61 61 61 53 59 59 45 40 26 40 61 93 124 135 138 142 144 146 151 152 158 165 168 168 165 161 164 173 172 167 172 167 180 198 198 193 199 195 194 198 200 198 197 195 190 65 35 68 59 59 62 57 60 59 50 44 32 54 90 115 132 137 138 140 144 146 146 156 165 168 174 176 176 175 168 168 169 171 175 171 172 192 194 184 198 205 201 194 195 193 195 192 186 57 38 72 65 57 62 58 57 60 54 49 47 79 116 130 138 141 141 139 141 143 145 157 164 164 166 173 174 176 179 179 176 181 189 188 173 180 175 160 182 189 198 192 189 190 190 188 172 46 44 64 66 59 62 57 56 62 53 50 66 103 133 137 141 143 141 136 132 131 136 127 118 111 107 108 123 131 143 154 158 166 177 181 175 170 159 148 171 161 176 185 192 194 188 190 162 53 49 58 63 61 61 55 56 61 51 50 81 116 139 142 142 146 144 136 128 119 112 97 85 90 91 88 92 90 80 81 84 106 122 132 144 145 144 147 163 147 163 173 181 190 187 191 167 61 48 53 61 61 58 54 56 61 51 53 89 123 140 144 145 146 147 136 122 107 99 95 92 90 87 83 76 67 52 46 52 63 69 83 96 119 132 148 159 136 137 143 138 143 152 156 156 70 48 50 59 61 57 54 54 61 52 56 93 124 135 140 144 148 150 140 125 114 101 80 54 56 54 41 41 33 40 39 35 49 60 63 74 107 129 147 147 116 111 100 77 76 86 108 111 73 49 50 60 62 60 57 55 63 59 56 89 121 134 139 146 151 152 150 141 127 111 96 77 85 70 32 31 37 91 65 50 48 59 73 83 112 136 155 130 60 46 38 40 43 81 116 91 72 52 48 58 62 62 59 53 61 59 52 85 114 134 140 147 154 159 158 153 145 143 150 126 121 125 68 45 89 137 95 70 78 75 95 109 131 153 171 94 23 16 32 82 82 65 113 77 71 54 48 56 62 62 60 53 60 56 52 75 108 133 141 149 158 166 169 167 163 156 155 146 112 119 134 127 142 140 121 117 129 114 120 129 146 174 191 98 46 33 33 109 147 98 109 67 73 55 50 56 64 64 61 58 61 53 54 64 106 129 140 148 159 169 175 176 174 165 159 156 145 120 115 124 127 131 133 141 147 142 141 147 161 182 202 154 114 96 100 158 158 153 123 61 76 57 48 56 64 64 63 62 61 54 55 44 97 131 137 147 158 168 177 181 183 179 170 168 169 165 155 152 151 152 154 162 165 158 153 158 168 187 206 186 147 135 144 145 152 178 115 57 74 58 48 58 64 63 63 59 63 55 53 66 104 130 132 144 153 162 170 180 185 187 181 178 182 180 177 173 171 171 177 176 172 164 161 167 164 185 207 197 173 152 141 141 161 191 104 54 69 60 48 57 65 62 60 57 64 55 50 94 111 124 130 135 150 159 163 172 179 184 184 178 178 177 173 171 174 177 178 176 169 165 161 163 161 180 205 201 183 171 177 178 180 194 101 55 65 60 47 55 65 63 59 58 63 57 52 90 105 117 122 130 143 153 157 163 171 174 182 183 182 178 174 175 175 177 175 172 163 161 159 157 162 178 200 201 188 181 172 177 187 198 98 57 63 61 48 52 61 64 63 60 65 57 51 95 104 113 117 127 136 145 152 156 162 162 165 173 177 182 183 183 180 181 177 165 153 154 152 153 160 174 193 200 188 185 180 182 192 196 101 60 60 56 49 50 60 66 64 62 64 59 53 99 104 111 112 118 132 142 147 155 158 160 159 162 171 176 184 186 183 180 169 154 141 135 145 155 164 180 196 205 188 189 188 189 193 192 98 61 64 55 49 49 60 66 63 64 63 60 57 99 105 108 112 113 125 139 143 150 155 158 164 169 174 176 182 183 182 177 163 141 133 147 151 164 170 185 200 210 194 188 192 186 185 180 88 64 67 60 46 50 59 65 64 64 64 59 56 101 103 108 109 109 118 134 143 143 147 155 159 166 171 174 177 179 178 172 153 129 143 161 159 166 171 186 197 207 203 185 191 183 179 164 73 67 67 66 48 50 57 65 65 63 64 61 57 103 108 114 112 110 115 128 138 144 145 152 156 159 164 168 172 172 169 161 139 125 147 156 161 162 164 180 188 188 197 185 187 181 180 137 65 70 68 70 52 47 53 62 65 63 65 61 58 105 109 112 120 113 112 122 134 141 149 150 153 155 159 164 167 167 162 152 134 115 126 119 106 99 109 141 158 150 155 175 184 176 175 106 63 70 68 68 50 46 50 57 63 63 64 61 59 107 110 110 117 117 114 117 128 137 147 148 150 153 156 161 162 163 156 150 148 105 70 45 26 25 47 73 74 79 128 177 180 173 157 77 66 68 67 68 52 49 51 56 62 62 62 62 60 101 107 108 114 115 114 117 125 134 143 148 149 152 154 158 160 158 155 160 158 132 88 73 73 64 52 66 91 138 160 174 173 171 125 64 67 63 64 68 54 50 49 54 60 60 60 62 60 98 105 105 109 111 114 117 125 131 139 145 148 153 153 156 157 156 161 168 165 153 139 122 115 105 89 103 150 182 161 171 173 162 89 64 64 62 64 69 56 48 49 56 58 60 59 62 60 89 99 108 106 109 111 119 120 125 134 140 146 152 153 153 153 156 159 162 160 150 136 129 133 133 122 133 148 178 168 168 175 132 61 67 66 65 63 69 57 47 50 55 58 59 61 62 60 89 96 105 107 105 107 117 120 123 124 133 141 149 153 151 145 151 145 139 140 138 128 126 124 129 125 136 142 164 172 168 168 87 58 67 63 62 61 69 57 39 44 55 56 59 63 62 62 84 91 92 98 102 103 113 119 121 118 128 138 146 151 147 142 140 128 127 128 129 126 135 140 135 130 143 146 149 166 174 131 62 65 62 59 67 63 68 83 89 65 42 52 60 60 62 63 77 84 84 91 99 101 107 112 117 118 122 134 145 149 144 134 127 127 129 130 134 125 126 132 152 153 151 150 151 165 171 87 59 65 64 61 58 86 122 138 208 207 154 71 52 56 55 56 69 77 83 85 93 91 102 112 116 118 119 127 140 144 142 131 112 95 85 75 62 58 56 59 87 88 83 127 142 165 149 62 65 62 59 77 113 192 156 84 185 196 197 168 81 70 75 69 58 65 73 82 81 79 95 107 114 116 116 123 136 142 136 132 131 102 71 58 49 41 33 41 36 49 60 99 136 168 111 53 63 71 138 186 203 195 146 87 91 72 79 95 103 82 61 74 55 57 68 75 76 77 84 96 106 110 111 121 130 138 136 142 153 159 152 152 154 145 133 136 147 158 156 155 147 158 74 57 60 123 181 174 126 89 72 67 57 43 55 67 76 86 60 45 51 45 52 68 75 73 77 88 96 100 104 113 115 121 134 146 149 146 149 148 155 168 174 179 178 169 169 174 161 131 44 47 82 150 168 136 104 75 66 80 67 58 48 54 68 88 121 102 51 45 38 53 66 65 70 86 92 96 102 103 109 116 130 136 136 133 136 138 137 135 128 130 143 158 165 164 147 87 62 74 123 160 170 100 99 107 79 71 86 75 57 45 49 65 122 130 43 48 40 39 55 61 59 71 82 87 88 93 105 118 123 128 130 124 111 98 94 88 67 55 84 129 147 148 105 48 82 142 161 164 164 76 72 85 100 88 72 90 84 54 48 54 73 100 73 36 44 31 37 53 51 55 67 74 77 87 97 108 118 125 132 122 106 86 80 82 75 73 83 110 129 126 46 22 130 177 196 193 166 72 52 54 73 100 92 75 99 95 65 68 61 63 91 65 42 37 22 28 39 44 57 68 74 83 92 101 119 131 143 141 134 136 140 139 134 136 139 138 136 85 23 114 202 198 199 180 173 98 36 86 130 150 137 99 77 101 99 72 56 43 77 82 79 70 56 28 20 25 36 50 63 73 83 98 111 124 139 156 160 159 169 168 165 163 159 149 114 43 26 133 183 192 177 152 137 130 125 139 173 195 186 137 101 88 101 105 70 46 77 72 84 87 87 81 64 37 20 31 40 46 65 88 108 110 125 149 157 153 162 164 158 159 154 140 78 21 11 61 144 168 173 157 138 150 148 132 159 182 183 136 106 116 95 106 109 82,Training\\n'\n",
      " '0,151 150 147 155 148 133 111 140 170 174 182 154 153 164 173 178 185 185 189 187 186 193 194 185 183 186 180 173 166 161 147 133 172 151 114 161 161 146 131 104 95 132 163 123 119 129 140 120 151 149 149 153 137 115 129 166 170 181 164 143 157 156 169 179 185 183 186 186 184 190 191 184 186 190 183 175 168 160 147 136 135 167 136 108 153 167 149 137 111 90 134 162 121 122 141 137 151 151 156 143 116 124 159 164 174 169 135 144 155 153 164 170 176 178 177 178 187 185 181 182 183 181 178 170 164 158 148 144 130 136 173 130 97 137 167 157 138 113 90 138 168 109 123 146 151 152 155 127 113 159 167 170 171 142 131 140 154 162 168 169 169 164 168 173 176 179 178 176 173 172 170 161 154 152 146 145 137 124 130 171 124 102 133 164 152 138 110 86 154 149 100 139 153 151 136 113 142 159 161 174 150 127 136 140 154 164 163 167 173 172 171 170 167 168 172 167 162 161 160 163 163 154 145 146 140 133 122 135 167 127 101 126 164 147 132 95 91 166 115 113 158 143 121 134 153 153 164 162 131 130 136 146 155 158 155 157 163 163 158 159 159 161 165 156 153 156 159 163 163 150 149 150 146 140 137 122 147 154 116 97 133 164 142 123 77 117 147 95 149 127 129 153 142 165 171 136 116 129 130 139 140 149 153 147 146 150 150 155 151 155 156 153 152 157 165 165 160 150 156 156 148 141 135 135 132 147 141 110 97 143 165 142 101 66 151 117 136 125 148 139 153 173 159 118 116 119 123 131 134 145 145 137 142 151 157 159 153 154 153 150 159 170 171 167 160 160 159 158 152 141 145 144 140 119 144 133 106 101 151 148 130 70 119 148 129 143 146 134 165 165 134 121 123 121 125 129 136 150 159 163 165 161 157 155 147 150 148 135 156 171 169 171 166 165 165 158 153 146 147 150 137 122 112 144 122 94 111 158 143 91 74 155 134 147 131 154 167 153 107 125 129 134 137 134 136 154 168 174 171 168 163 156 151 150 146 146 166 171 173 176 177 191 187 175 180 179 174 165 142 134 108 111 137 108 86 143 156 116 64 133 143 129 138 162 167 132 117 127 128 140 147 145 155 159 165 170 172 166 160 154 156 160 156 156 158 153 170 188 198 208 203 209 219 217 200 174 171 147 128 92 129 131 88 103 159 135 75 111 133 126 160 156 159 117 132 129 131 144 160 165 162 166 170 165 160 160 159 153 149 150 151 148 120 132 189 183 180 177 187 201 194 186 181 170 167 146 118 117 100 139 112 74 139 145 85 91 120 151 156 164 129 111 135 140 139 142 158 163 172 190 195 189 168 156 149 143 137 140 140 132 114 142 150 129 133 125 138 140 132 114 124 131 118 143 125 126 82 97 141 72 113 152 93 77 134 157 149 166 95 124 136 142 156 165 179 189 198 198 186 186 188 157 126 124 118 129 128 115 95 100 90 84 81 66 72 80 77 63 59 65 70 67 86 105 82 95 138 89 94 153 106 74 153 148 165 134 80 134 137 149 173 187 193 201 185 169 141 128 150 139 113 119 123 128 114 91 71 60 51 69 78 80 80 79 76 76 65 65 85 103 46 73 142 85 114 114 75 145 121 70 150 141 168 76 91 130 144 179 197 210 190 164 146 128 121 90 92 90 90 114 104 109 110 81 52 53 87 96 94 99 96 88 95 108 116 110 97 120 98 64 120 77 105 130 67 131 128 67 137 150 136 46 106 126 164 164 151 150 131 115 103 88 90 91 92 78 56 49 65 90 115 66 29 91 99 104 107 88 94 105 111 118 113 116 103 103 120 47 83 110 120 134 67 116 136 74 133 163 82 51 113 115 104 112 144 162 138 104 96 93 95 90 91 99 103 55 29 46 45 16 40 104 95 101 92 93 96 80 69 82 99 98 108 116 128 70 102 117 127 140 79 105 139 82 140 149 23 43 103 50 78 179 185 147 111 113 117 106 91 95 100 91 96 92 19 6 19 8 35 88 64 66 60 72 68 34 35 70 85 101 118 130 143 82 114 125 130 149 93 104 139 83 148 130 67 86 94 42 142 173 151 128 124 106 96 103 90 89 100 97 95 103 28 48 127 126 38 87 81 68 64 70 74 51 68 92 112 139 149 152 158 100 134 128 133 159 105 95 139 86 153 113 62 126 130 62 135 136 127 122 93 67 54 44 42 43 60 76 86 104 41 115 197 211 112 67 118 109 107 93 84 83 101 108 129 150 158 156 143 105 140 129 131 166 115 85 137 87 156 99 21 89 104 46 117 135 113 78 52 89 94 46 24 45 54 65 95 92 49 161 213 212 188 85 97 133 130 124 121 122 136 147 143 154 151 173 124 115 147 129 124 164 136 95 126 85 159 94 36 97 117 78 93 130 90 73 77 94 86 61 60 72 69 91 113 80 76 188 214 213 200 143 66 119 138 150 151 151 159 163 156 154 162 140 107 136 148 135 115 158 150 116 111 87 161 101 50 109 111 98 69 99 97 109 111 114 106 95 96 99 101 109 122 70 111 193 214 217 200 183 115 78 124 157 167 170 172 166 161 147 127 118 134 138 141 141 119 147 155 131 98 96 163 103 72 120 112 115 80 100 117 100 105 127 138 133 132 140 137 121 103 64 153 200 215 218 205 183 169 127 77 92 111 122 126 128 128 129 135 145 141 138 133 138 127 139 169 127 83 93 161 106 87 122 106 117 114 88 124 116 108 135 150 151 156 163 162 121 66 110 177 201 212 214 200 181 162 155 117 97 103 109 115 119 131 141 147 149 141 146 140 128 130 140 170 101 87 89 163 109 105 123 103 112 133 113 95 132 139 160 167 169 158 149 118 72 89 133 169 189 197 204 194 180 172 166 138 114 112 114 120 119 125 134 140 150 145 142 145 142 144 152 164 116 95 84 159 113 111 124 101 112 136 134 115 107 118 131 138 129 108 93 75 88 112 136 170 183 181 178 181 177 177 180 175 130 110 119 125 130 131 135 138 142 146 136 130 146 142 157 169 135 91 100 150 115 114 138 107 114 133 125 124 133 137 128 119 106 102 98 93 96 141 160 147 149 150 145 153 161 147 146 175 162 114 112 121 127 128 131 129 134 142 136 124 139 141 157 175 138 106 149 145 119 119 150 109 115 136 129 126 131 137 130 114 106 108 109 99 115 156 138 116 134 139 130 140 119 53 45 103 139 131 101 98 117 126 130 123 124 133 137 131 130 143 160 177 148 158 182 146 122 117 161 118 116 131 134 130 130 124 121 118 117 119 112 92 107 134 74 29 73 122 129 126 78 33 42 65 107 123 103 97 96 113 121 119 121 124 131 130 128 157 176 179 185 187 181 158 124 111 169 131 116 123 129 130 129 129 128 125 124 114 86 89 104 91 46 31 35 74 113 107 93 79 79 94 121 131 126 119 92 100 114 114 117 115 120 125 130 164 179 188 192 182 184 182 140 106 170 147 120 121 129 130 127 128 129 128 123 98 62 98 116 113 94 90 85 81 80 104 116 126 141 136 148 148 129 122 101 95 107 107 117 123 125 130 139 165 179 184 192 184 183 191 167 119 173 158 136 118 130 131 125 123 123 125 114 81 71 131 147 148 138 133 117 101 88 118 131 143 163 167 165 164 146 132 122 107 95 104 115 126 136 137 146 168 180 179 195 187 183 188 186 141 158 165 147 116 131 130 124 118 117 119 102 70 101 140 154 153 142 134 125 118 117 118 116 120 137 149 163 172 158 144 137 138 117 112 123 129 139 146 157 167 175 178 196 190 184 190 188 167 155 174 161 134 119 114 121 118 113 109 89 93 134 140 161 170 145 126 108 121 117 108 117 136 146 142 138 150 149 147 135 142 122 115 142 149 144 144 162 168 171 176 192 187 182 192 183 185 175 174 145 87 65 63 84 112 114 98 92 109 140 155 151 147 123 103 111 112 116 108 111 127 130 117 115 124 129 138 124 118 120 114 135 144 141 144 154 168 170 174 187 182 179 187 184 184 187 132 28 6 24 36 39 69 111 99 84 109 134 133 108 97 84 75 78 74 81 80 62 48 32 27 36 42 56 88 87 86 123 130 138 138 134 141 151 170 167 173 189 184 181 187 186 191 192 63 26 18 3 16 22 23 85 106 98 110 112 89 47 35 41 20 18 21 13 9 7 3 2 4 4 3 4 30 40 49 112 129 142 143 139 144 151 171 174 177 188 186 181 189 189 170 124 47 33 28 8 4 12 11 48 111 113 100 85 50 19 4 5 3 10 14 12 15 26 31 35 38 37 40 62 84 73 61 124 143 138 130 140 139 152 157 170 179 186 186 181 179 115 39 26 14 6 10 3 1 5 2 48 124 117 106 71 34 42 32 17 17 24 35 41 49 63 67 70 72 88 106 118 107 97 75 95 139 138 125 130 131 150 160 173 183 188 186 184 114 54 84 157 71 0 6 5 4 3 0 75 122 109 103 69 53 67 68 59 55 54 59 65 74 88 97 104 109 119 129 128 127 130 98 96 136 156 130 117 128 148 165 176 190 191 186 183 74 64 167 201 164 43 1 0 0 3 46 114 118 110 110 67 66 97 83 86 87 98 93 98 102 112 119 119 125 126 130 128 127 135 134 112 123 150 136 118 126 146 158 179 196 188 185 185 142 50 136 182 194 173 83 58 60 100 130 121 113 120 116 80 77 95 103 111 116 124 116 120 117 119 108 123 129 144 160 143 129 130 127 132 123 149 132 117 125 142 151 188 194 187 184 185 197 128 84 169 177 199 178 162 147 154 146 124 107 129 120 96 88 99 131 131 145 131 137 148 131 133 128 124 118 142 167 159 130 136 134 127 128 143 133 118 139 140 144 192 196 187 184 184 188 188 121 86 175 189 192 157 148 144 149 126 113 123 127 106 96 107 145 143 144 131 147 150 143 147 134 126 131 151 170 162 148 116 139 122 124 141 127 112 128 116 113 159 201 185 185 186 188 187 196 129 85 171 194 171 142 144 144 128 119 116 121 116 100 108 136 146 128 135 151 146 152 150 158 143 133 143 159 153 152 128 137 133 125 127 102 108 109 105 102 106 197 186 182 187 186 184 185 197 124 84 174 185 150 129 143 135 115 102 111 124 112 109 132 146 135 149 148 143 163 156 159 150 139 128 116 125 133 109 130 147 130 121 105 108 95 108 102 67 171 193 183 184,Training\\n'\n",
      " ...\n",
      " '0,17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 92 164 195 220 150 123 190 168 86 82 134 183 198 91 106 89 30 78 114 110 100 76 39 24 38 76 52 34 48 109 83 114 245 18 17 16 22 21 25 21 20 23 28 27 28 24 16 26 94 197 220 227 163 151 241 214 219 207 189 207 225 169 136 220 141 75 95 103 78 50 35 37 135 213 163 79 69 120 104 136 253 19 16 17 17 18 24 24 22 23 22 33 33 29 17 21 83 226 222 242 141 158 227 213 225 232 216 215 223 225 119 210 236 172 117 106 59 34 24 21 94 227 213 100 51 113 128 152 255 22 14 15 14 19 22 24 29 35 19 27 30 32 24 23 58 198 200 172 157 186 198 201 190 202 213 209 223 234 168 150 227 192 149 75 51 21 99 75 21 176 164 68 81 113 141 153 235 37 19 13 12 20 24 19 37 33 17 24 29 24 29 24 24 88 89 58 72 73 80 102 116 143 178 208 222 223 222 161 191 192 145 74 132 39 69 57 36 94 86 100 135 125 138 151 199 64 32 14 11 20 23 17 31 18 16 21 23 18 26 21 14 30 27 30 25 22 42 62 84 115 138 191 211 214 234 193 191 180 95 55 101 89 102 108 118 129 155 145 140 125 144 149 208 78 60 18 14 18 15 17 21 19 22 16 14 16 20 23 18 24 29 34 47 67 88 108 122 123 126 160 195 214 221 219 206 197 125 87 137 157 169 187 185 181 179 164 137 133 143 142 196 103 89 26 12 19 16 18 16 18 22 18 14 14 28 41 33 89 93 65 56 86 111 149 177 187 193 193 192 201 219 240 235 219 201 111 152 191 193 190 180 184 176 150 137 157 146 142 177 107 109 39 21 17 19 13 12 19 31 20 12 12 47 64 37 78 118 151 141 90 88 108 137 174 189 208 213 209 222 233 237 211 207 159 98 135 165 179 181 184 181 173 166 158 156 145 154 85 90 82 72 18 18 19 14 17 50 27 23 20 59 53 17 84 238 255 253 210 133 112 129 170 174 181 212 203 203 216 224 215 203 185 144 95 114 146 155 173 182 179 176 164 156 152 147 116 66 119 92 15 27 21 19 23 42 36 38 37 49 24 34 30 89 240 241 239 155 89 129 190 202 184 194 190 190 206 218 217 219 210 196 148 119 145 158 152 168 173 172 163 154 149 152 138 77 140 85 33 94 45 12 25 57 52 48 53 71 19 92 119 23 210 255 162 83 92 140 190 211 185 176 192 208 210 209 216 216 216 224 201 147 137 173 166 174 175 180 163 157 154 150 86 109 153 67 88 179 150 93 36 57 74 58 103 184 39 34 40 48 166 161 105 131 160 177 203 214 193 174 191 203 215 209 213 220 221 225 225 187 121 164 189 188 186 181 172 164 155 150 84 155 148 57 153 204 196 202 155 128 99 83 101 139 91 65 96 118 153 168 198 193 183 209 227 213 188 188 197 210 216 212 210 222 228 229 226 216 166 128 169 194 198 190 176 169 149 142 72 171 154 107 170 215 210 216 214 200 174 144 149 136 165 182 206 214 226 219 212 197 195 206 208 201 196 199 202 220 223 218 214 225 228 228 227 214 187 125 132 182 199 197 191 178 145 137 40 139 180 164 174 221 222 230 228 214 200 192 203 204 217 222 225 228 220 215 212 203 203 200 205 207 210 206 210 222 227 222 220 223 219 213 213 209 204 162 107 133 180 193 198 183 157 137 32 117 187 184 183 224 229 237 238 231 229 218 213 214 216 219 225 230 220 207 205 210 214 216 219 225 220 216 219 219 221 225 215 219 216 211 215 216 216 208 153 109 131 174 198 189 170 144 30 106 182 205 213 220 231 235 239 232 234 231 224 222 227 224 223 217 207 204 216 222 218 223 229 233 233 230 215 203 215 229 214 207 207 210 220 217 220 229 215 159 125 168 191 197 182 154 39 116 183 200 208 221 227 228 236 233 232 229 225 230 227 223 225 225 222 222 229 227 229 232 233 234 235 232 209 191 205 216 204 192 192 208 212 213 227 239 231 199 135 170 204 209 192 165 68 120 179 197 198 218 220 219 231 233 229 224 229 232 227 226 234 232 227 229 229 231 239 242 238 234 235 223 202 175 181 174 182 205 193 205 220 231 245 241 229 182 120 170 210 214 204 179 79 123 172 190 194 207 216 216 219 227 224 225 234 232 232 234 235 232 234 232 238 240 244 246 242 235 230 220 178 163 172 175 197 217 212 212 219 223 233 230 209 150 98 143 203 216 210 188 69 123 159 177 186 201 211 219 219 221 223 230 236 233 235 235 233 232 235 235 243 243 245 246 242 231 222 225 161 168 191 206 230 244 246 235 211 207 212 219 177 122 76 106 166 211 220 206 63 103 150 169 176 190 205 210 217 216 221 231 236 231 230 232 235 238 234 238 242 245 246 243 238 220 216 235 174 177 199 205 189 150 148 150 163 154 181 178 101 68 84 87 112 168 208 213 72 102 130 158 168 177 189 199 209 210 214 225 229 230 230 231 232 235 237 238 242 243 243 241 234 216 212 242 203 160 155 166 175 132 158 175 183 124 111 100 48 66 93 81 81 102 161 201 57 109 122 150 168 171 175 190 197 208 207 218 222 223 229 232 231 231 235 242 245 242 242 242 231 216 219 243 241 189 147 190 205 200 197 199 187 175 138 96 67 83 119 93 87 93 109 142 36 73 106 138 160 174 174 178 190 206 203 213 218 220 226 231 231 232 237 238 241 242 243 241 231 218 229 241 233 232 217 189 167 181 184 171 164 149 116 86 88 119 147 134 119 100 117 113 22 40 89 131 159 165 174 180 193 202 202 211 219 219 222 231 235 234 234 237 237 238 239 237 231 222 233 232 227 216 210 193 180 180 187 175 159 137 95 118 142 176 189 192 183 141 115 124 21 27 61 108 138 164 165 177 193 196 201 213 214 213 220 229 233 235 233 237 234 236 238 236 233 224 233 228 221 211 208 202 194 185 178 175 161 157 162 193 215 221 224 205 194 192 165 133 22 23 42 91 112 136 153 167 185 204 208 216 217 216 221 232 233 236 237 237 234 235 236 239 233 229 234 223 211 205 203 207 209 197 192 183 175 209 230 229 233 216 171 145 183 182 156 141 32 20 34 75 93 111 132 157 184 200 208 218 220 219 226 233 231 235 235 235 238 238 238 240 238 233 226 215 200 206 204 202 215 221 207 213 227 233 238 224 189 100 54 130 126 87 95 91 63 37 32 63 78 103 118 139 169 179 198 217 222 217 223 233 234 236 234 235 238 237 239 243 242 234 216 205 200 199 203 204 216 216 224 236 237 230 191 135 75 31 166 236 101 100 112 113 88 87 45 43 62 89 114 130 152 168 184 209 212 219 227 236 233 235 236 233 236 238 240 247 243 237 215 202 198 195 189 203 211 222 237 240 205 124 89 105 117 183 208 146 114 122 136 142 85 112 100 48 50 67 93 120 136 155 166 195 209 218 228 231 233 234 234 236 241 240 242 245 243 229 212 196 204 207 208 205 225 242 246 176 67 114 131 159 206 162 127 148 176 172 156 159 99 97 124 88 46 56 78 115 124 134 164 179 206 212 220 229 232 232 236 236 237 242 244 246 243 223 207 204 192 207 220 223 237 246 177 84 85 116 120 129 160 183 206 215 206 187 161 142 96 106 107 107 59 49 68 92 114 129 151 162 180 203 211 217 220 226 238 235 239 241 244 245 243 227 218 204 190 202 215 230 239 170 102 116 123 128 175 205 225 226 208 197 173 157 139 129 97 110 110 112 87 45 56 77 110 121 145 155 172 192 199 211 215 219 232 228 232 231 243 244 240 231 218 205 204 208 216 220 192 150 157 169 186 208 222 224 213 178 158 171 155 142 150 169 99 114 119 129 121 84 47 64 88 115 131 159 162 158 181 197 201 210 232 225 215 229 241 240 239 229 217 216 205 224 213 189 204 219 220 223 216 213 210 205 190 167 158 181 182 178 180 184 80 109 128 130 133 115 71 51 81 102 130 154 158 163 178 194 200 205 210 224 216 226 227 231 240 232 222 213 210 208 181 194 222 216 223 224 221 207 193 199 197 203 206 203 200 189 202 188 50 97 117 123 146 135 99 58 65 94 131 145 164 154 160 179 181 206 199 205 201 210 212 226 233 235 228 223 207 193 206 220 226 231 229 232 235 230 226 227 224 225 232 218 202 204 207 198 24 78 103 126 138 153 125 82 53 74 105 100 125 165 165 155 177 208 208 199 200 207 221 219 225 227 227 217 204 208 217 226 231 238 238 241 237 241 239 240 240 225 222 201 181 203 207 206 12 60 99 109 130 148 152 115 65 57 86 92 122 158 159 163 173 188 192 198 211 217 219 218 226 226 226 220 206 201 216 229 231 241 244 242 243 240 238 237 235 226 222 206 197 205 213 207 22 32 64 85 107 129 135 127 98 60 57 82 122 140 156 156 142 158 168 174 177 183 214 215 223 209 211 219 208 203 223 217 213 240 234 216 226 223 227 222 218 220 222 200 202 193 187 188 9 10 61 106 126 149 146 130 118 102 54 39 81 119 134 122 118 165 193 194 202 185 187 213 212 209 208 222 203 199 223 206 207 230 233 210 224 240 241 238 215 208 228 212 196 198 202 207 0 13 65 94 110 130 157 147 117 117 84 31 45 94 103 108 137 162 172 180 208 202 180 199 214 202 200 210 189 192 219 204 199 221 220 195 218 233 225 234 211 206 235 218 197 206 202 196 2 19 50 70 94 122 147 143 128 128 104 52 35 64 76 88 113 126 154 165 183 190 183 195 218 186 182 195 178 172 198 197 186 208 207 187 212 227 219 226 229 225 226 210 190 193 198 188 4 21 46 59 92 119 138 132 126 147 130 74 59 55 35 56 82 88 110 137 164 174 166 186 213 191 172 163 161 153 167 163 160 206 203 173 193 217 210 211 213 213 215 211 193 186 180 187 5 17 41 53 83 107 136 123 125 148 140 93 83 83 44 24 53 73 80 95 124 121 136 157 171 167 150 148 141 134 140 145 145 167 178 159 191 221 212 204 207 210 202 202 176 177 172 176 20 15 22 37 68 94 105 114 141 158 139 116 104 105 87 44 32 41 54 62 66 72 88 123 131 122 106 119 137 125 112 112 123 150 157 164 176 199 190 179 193 193 194 170 148 154 133 113,PrivateTest\\n'\n",
      " '3,30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 61 78 108 142 147 123 113 111 107 113 125 136 145 137 118 101 85 64 59 71 83 85 81 96 109 102 94 84 80 71 60 50 44 30 27 28 29 32 30 51 72 73 76 68 63 58 49 39 38 58 73 71 105 124 112 104 108 113 124 132 141 131 115 94 77 66 79 90 88 96 113 120 111 91 78 76 75 72 64 52 40 31 28 30 33 33 32 63 78 77 80 68 38 33 38 83 39 61 75 39 47 98 118 102 102 116 126 139 147 129 106 89 76 81 92 87 95 102 93 82 66 56 53 59 63 65 61 54 37 30 30 32 38 33 35 75 84 95 98 85 84 75 66 75 56 48 34 54 70 70 117 106 98 117 126 142 146 128 101 82 73 78 92 96 83 62 48 49 51 46 50 48 46 56 57 56 36 31 30 31 36 32 45 83 90 106 112 108 108 121 126 102 98 106 96 98 92 56 104 107 104 113 132 146 150 128 103 82 67 94 101 77 46 32 64 93 30 33 36 48 47 46 51 55 38 30 28 34 45 39 58 84 95 113 121 128 117 111 118 119 122 112 120 123 117 98 110 119 112 120 137 153 150 122 99 75 72 108 88 56 85 49 37 49 31 56 42 31 42 42 50 56 37 31 29 32 54 49 67 87 100 118 127 140 148 141 126 112 105 103 101 105 115 132 132 125 120 131 148 162 158 127 96 71 90 105 70 78 100 65 47 44 41 64 49 36 37 46 52 59 36 31 29 30 56 64 72 90 106 119 131 143 154 157 151 145 140 140 141 141 145 135 126 124 125 138 152 160 156 133 100 87 101 105 95 95 96 88 78 61 54 54 65 64 55 55 63 63 35 32 29 27 52 82 76 93 109 120 132 144 158 160 158 157 157 157 160 161 155 141 131 127 132 141 151 160 152 132 108 102 114 110 104 87 78 75 74 69 71 75 70 71 79 75 70 65 37 31 31 27 45 84 78 97 108 115 131 145 156 163 167 166 165 162 163 162 154 141 136 133 137 147 154 159 153 133 115 107 124 122 122 114 104 87 77 76 76 77 85 90 87 79 70 63 36 32 31 28 40 63 76 98 112 122 132 147 157 160 169 171 171 172 169 161 148 140 136 135 137 152 158 162 154 133 121 117 126 134 137 140 138 124 119 120 119 124 124 111 98 84 73 62 38 31 30 30 36 52 69 100 114 130 138 155 165 170 177 180 179 176 170 159 148 140 139 144 140 145 158 160 155 140 128 120 122 136 148 153 152 145 140 142 142 144 134 117 102 87 74 59 46 30 30 30 49 61 69 99 110 127 144 157 165 177 184 184 179 173 170 164 150 137 136 149 158 152 156 159 155 146 131 121 122 134 146 161 163 160 155 151 147 145 128 109 98 83 72 65 40 32 27 41 162 141 77 99 112 123 146 157 168 175 180 183 180 177 170 153 140 136 137 156 166 165 159 159 159 150 127 118 126 138 144 159 169 169 163 164 157 141 125 106 90 83 76 60 31 31 29 31 74 78 69 101 109 116 143 156 167 169 171 175 175 171 156 155 157 144 148 165 170 169 166 164 163 155 136 119 122 139 153 156 168 175 171 167 157 139 120 105 91 84 77 44 33 31 29 29 27 35 64 99 109 110 136 151 156 163 167 170 167 145 147 179 173 156 158 175 178 177 176 173 169 160 146 131 126 125 150 159 168 175 170 163 157 141 117 95 90 87 70 35 37 30 28 29 33 25 61 101 112 113 133 147 152 159 161 163 154 115 108 129 171 169 162 176 186 189 189 187 181 166 153 146 154 154 140 155 166 174 168 161 153 138 118 101 92 88 59 35 33 31 29 28 31 28 58 101 112 119 129 142 146 147 152 148 131 105 83 73 90 126 137 147 168 177 180 181 179 163 149 157 165 150 126 141 162 168 165 158 141 127 114 106 92 79 46 39 36 33 30 28 32 27 53 98 109 114 122 134 135 137 144 131 107 114 108 94 79 71 97 121 139 156 156 151 138 124 122 121 96 77 96 131 149 155 155 148 136 113 109 101 86 87 55 40 39 33 31 29 31 27 46 94 107 111 118 125 128 131 127 105 108 135 141 130 116 96 81 97 121 130 126 112 91 71 58 51 53 69 99 127 138 143 144 140 130 115 108 97 78 106 82 32 36 34 31 27 31 29 37 86 106 112 116 119 120 118 102 94 123 143 149 146 139 124 104 81 80 84 82 75 62 64 73 84 94 107 114 114 128 135 133 127 119 114 100 91 79 123 51 34 34 33 30 27 29 32 31 76 102 109 116 120 117 109 98 117 135 144 152 153 151 146 137 120 85 70 70 78 100 110 120 124 129 125 107 108 118 123 121 117 108 104 92 80 74 97 45 35 35 32 30 27 29 33 27 63 99 106 113 117 121 110 105 117 136 144 155 156 154 154 160 166 158 143 139 147 146 136 134 133 125 114 94 89 104 113 113 108 96 90 83 77 57 27 34 36 35 33 30 26 28 29 28 44 90 104 114 121 123 115 89 92 126 143 158 159 157 155 161 171 173 166 166 166 152 139 133 126 118 107 89 65 81 102 101 97 88 81 78 70 40 36 36 35 33 32 30 28 29 30 29 30 77 98 110 121 127 114 102 79 61 101 122 135 143 153 158 168 179 173 170 164 142 130 128 124 117 103 87 72 65 88 93 89 80 77 74 56 32 37 36 34 32 35 32 27 27 28 29 26 53 92 106 115 128 118 120 139 99 113 158 122 121 117 126 138 156 157 148 146 127 116 118 115 113 94 77 72 72 82 84 77 78 77 68 40 28 33 34 35 32 34 32 29 29 26 29 28 32 77 101 112 122 125 132 148 149 143 189 199 195 153 156 135 104 103 111 93 97 88 84 73 60 51 56 66 84 89 84 74 74 76 55 29 32 31 32 35 32 33 32 27 29 28 28 29 27 51 90 104 115 124 141 151 147 149 163 181 210 218 222 208 169 180 185 150 161 143 111 68 68 81 94 79 96 94 82 80 75 66 34 30 31 30 35 34 34 33 32 27 29 27 27 28 28 36 78 97 105 120 136 148 150 151 156 158 166 189 215 219 218 223 216 209 190 161 123 100 106 122 120 94 103 95 84 77 72 42 25 32 30 30 38 34 32 32 30 27 27 29 28 28 27 38 65 86 99 110 125 137 146 147 152 165 170 158 157 167 171 178 177 156 142 133 121 105 111 128 122 101 99 86 81 72 49 28 27 36 34 31 39 34 29 30 29 28 27 29 27 28 28 42 68 77 93 102 117 126 134 140 138 132 157 182 177 165 160 165 170 166 154 137 118 113 114 124 118 100 83 76 69 48 28 27 27 33 35 36 40 32 29 29 27 28 29 29 28 29 27 49 76 76 86 102 113 125 122 127 137 127 117 130 155 168 168 170 162 144 130 121 117 108 109 113 107 85 69 62 47 28 27 28 27 33 35 40 41 34 31 29 28 28 27 28 27 28 39 63 81 84 79 95 115 129 125 110 117 121 114 104 98 102 109 109 101 102 111 111 101 91 99 99 84 68 56 41 29 26 27 29 28 34 34 37 39 33 32 29 28 27 27 28 32 44 56 71 86 93 80 82 109 131 140 120 106 96 102 105 98 95 98 97 98 100 94 83 80 87 91 79 69 53 36 30 28 26 28 31 29 31 33 37 39 32 31 28 26 30 35 46 57 62 67 78 90 97 92 77 96 124 143 145 131 113 97 89 82 80 78 82 81 79 73 71 89 96 82 68 54 35 26 29 28 26 28 31 28 29 32 37 38 32 32 39 47 56 65 74 74 72 76 86 92 99 100 85 76 110 136 146 152 148 139 125 114 105 97 96 91 90 91 103 110 92 72 53 30 25 29 30 27 27 27 31 27 30 34 38 39 32 33 63 72 81 89 85 81 80 87 91 97 98 98 92 80 90 119 135 143 147 152 151 144 143 137 135 135 131 126 125 108 77 51 28 26 26 31 29 26 27 27 31 27 28 35 37 35 31 31 78 86 95 97 91 84 88 94 97 103 101 101 93 89 82 92 119 129 136 143 143 140 143 144 145 144 137 128 110 84 52 26 27 27 27 33 27 27 27 28 32 28 29 36 35 35 32 31 86 95 101 99 94 92 95 97 100 109 102 104 99 92 89 77 85 104 112 119 121 121 129 129 128 124 112 100 76 53 32 25 26 27 30 34 27 27 28 31 30 27 32 37 35 37 33 33 95 103 101 97 98 95 99 104 104 110 108 106 102 92 89 83 66 69 76 85 86 92 100 99 98 91 80 66 47 35 31 25 26 29 35 33 26 27 28 30 30 28 33 40 35 34 33 34 98 104 100 98 102 98 104 112 109 111 111 107 103 97 86 82 77 65 53 56 66 76 72 66 58 50 45 39 36 37 32 26 26 30 36 31 27 28 26 27 28 27 33 39 37 36 31 31 99 99 97 103 106 107 113 114 113 114 116 114 108 101 93 83 78 70 60 51 46 45 42 39 39 42 40 39 40 41 35 27 26 32 36 29 27 29 27 28 29 27 33 39 37 35 31 31 101 98 101 107 105 110 116 115 117 114 114 114 107 102 96 88 79 71 60 54 49 45 45 45 44 45 43 43 45 44 35 27 26 32 34 28 26 26 27 27 28 26 32 37 34 35 30 30 103 102 106 109 105 114 117 121 122 119 111 110 104 102 99 91 84 77 66 58 54 50 51 53 52 50 49 47 49 44 37 29 26 34 34 27 26 28 29 28 28 26 31 37 34 35 30 30 104 107 107 111 110 114 118 124 128 126 116 115 107 99 96 95 89 82 76 70 64 62 61 60 58 52 52 52 52 50 40 32 26 35 32 28 26 27 30 27 27 27 29 35 35 34 30 31 104 109 110 108 112 114 117 126 132 133 119 117 116 97 92 89 85 84 80 78 72 71 74 67 56 57 60 57 59 55 44 35 28 38 31 28 26 26 30 27 27 26 26 34 35 35 30 30 102 105 108 107 108 113 116 124 132 136 124 119 117 103 96 91 89 84 82 79 81 81 78 65 61 68 68 62 63 56 45 37 30 38 32 27 27 27 32 27 27 26 28 35 35 35 31 29 93 96 100 101 104 109 117 120 134 137 129 123 122 106 97 92 91 90 87 84 89 91 79 64 70 74 73 69 65 56 47 36 30 35 33 29 28 29 30 27 27 26 28 35 35 35 30 28,PrivateTest\\n'\n",
      " '2,19 13 14 12 13 16 21 33 50 57 71 84 97 108 122 136 145 154 161 170 177 176 179 181 188 189 181 168 162 161 155 137 109 81 52 30 22 22 25 25 27 53 63 84 108 108 95 86 16 17 15 14 16 20 32 49 59 80 95 103 110 119 125 137 142 150 160 163 174 173 170 175 178 185 186 185 178 174 168 162 142 107 79 46 28 23 24 29 21 58 82 93 114 105 94 90 10 9 10 13 17 28 49 71 78 99 114 120 122 127 132 140 145 144 150 155 165 172 171 165 165 174 182 184 181 174 171 168 167 136 107 73 33 22 29 27 27 50 95 109 118 101 93 95 10 10 10 14 23 37 59 82 101 114 124 129 131 131 136 142 146 149 148 155 164 168 174 174 167 173 177 179 181 176 173 171 171 156 135 110 59 25 24 17 16 39 96 114 114 99 96 104 7 10 14 22 31 50 79 104 117 129 134 136 137 142 138 141 151 155 158 154 162 167 167 172 171 172 176 179 181 179 178 171 175 163 160 136 108 40 20 22 21 31 98 114 107 98 100 108 12 16 22 27 43 69 90 107 116 129 137 138 138 144 151 149 163 171 177 179 177 179 176 177 177 178 176 174 175 180 181 183 184 174 174 152 143 75 15 25 17 24 99 115 101 98 106 109 16 19 25 40 62 79 98 111 121 132 140 140 139 146 154 155 167 176 183 186 186 189 186 181 173 176 176 171 170 179 179 187 185 181 179 165 163 105 17 24 11 25 94 116 100 101 113 110 19 28 46 68 85 98 114 123 130 140 146 147 147 152 160 165 174 186 191 193 194 193 190 189 177 172 172 174 177 179 179 189 190 186 182 176 173 119 18 21 13 19 82 113 103 109 118 113 37 55 80 96 106 115 120 128 134 137 143 151 150 151 158 167 175 181 185 192 195 196 193 193 188 183 179 180 186 182 184 193 196 194 192 183 183 137 13 16 13 22 74 104 106 119 120 115 66 88 102 110 116 122 126 131 140 145 144 150 155 151 152 156 166 172 174 184 188 192 189 188 189 186 184 189 189 191 195 198 193 194 192 186 190 147 5 11 14 22 64 94 105 123 123 115 97 103 112 118 120 120 126 133 140 153 155 158 165 164 160 154 152 160 165 172 179 182 186 185 182 184 183 188 184 190 194 193 187 184 183 187 203 151 1 9 15 23 54 89 111 115 125 117 117 114 111 117 123 123 126 134 144 154 162 167 174 174 164 160 152 150 150 156 171 172 181 185 185 187 188 189 181 185 192 189 179 174 180 196 215 148 0 9 15 26 49 72 114 115 119 115 117 123 116 121 124 127 131 135 144 153 167 177 186 191 184 182 178 168 166 158 165 167 166 171 174 181 183 186 183 177 182 179 182 190 200 207 217 138 0 11 14 23 38 56 103 123 113 112 114 125 127 122 125 128 136 136 145 156 168 181 186 187 185 189 189 186 180 172 169 160 155 159 161 173 168 169 176 166 166 177 188 193 194 182 209 124 0 13 14 24 33 42 78 122 116 112 122 125 133 126 128 130 135 142 136 121 114 122 122 119 108 108 122 137 131 144 158 149 140 152 164 167 164 169 167 148 144 146 136 122 95 70 154 100 0 14 15 26 35 34 51 101 125 118 128 126 129 134 125 128 132 145 146 143 144 147 149 146 137 134 114 94 77 69 92 104 111 126 145 159 165 171 140 91 77 68 68 82 108 129 180 85 0 16 16 27 32 35 41 67 125 122 130 131 130 135 132 121 123 124 129 133 134 126 114 96 82 76 61 66 71 87 101 104 104 122 140 150 165 162 114 90 65 44 38 49 78 114 177 69 0 16 18 27 29 35 41 45 109 129 133 138 141 135 140 125 114 110 89 59 53 52 64 81 34 29 26 23 51 96 119 121 126 137 150 163 173 147 87 65 84 88 43 33 11 41 148 56 1 18 19 29 29 26 35 38 76 128 135 140 147 149 150 145 114 89 59 40 35 100 161 183 100 51 51 43 41 91 108 119 137 160 181 199 198 121 67 88 172 201 78 54 41 87 188 43 2 18 21 31 27 23 30 36 53 98 140 144 150 153 155 163 153 124 98 96 73 67 93 133 131 69 63 89 71 124 117 126 148 176 202 219 205 143 84 98 134 136 91 70 91 188 215 37 5 19 23 33 23 20 26 30 40 62 143 146 153 158 165 170 179 164 131 120 118 121 130 127 143 154 151 147 158 151 145 146 162 183 217 235 216 166 139 119 113 133 142 141 158 221 213 31 7 22 25 35 25 20 23 25 33 48 140 145 153 162 169 176 179 179 161 142 125 126 135 147 151 147 138 137 163 171 161 156 166 189 217 239 220 194 172 125 108 122 148 160 185 227 212 33 8 24 26 40 22 15 21 23 26 41 137 144 153 161 169 177 182 187 183 177 164 138 127 133 137 145 157 176 201 189 168 162 172 195 215 237 225 206 210 187 163 156 154 177 208 227 214 36 5 31 38 40 23 11 20 28 28 32 132 138 151 164 174 181 189 190 195 198 198 192 187 184 185 184 187 205 208 187 165 157 178 195 210 234 228 208 208 209 199 196 205 216 221 227 209 32 8 38 39 31 16 12 17 22 30 26 126 133 145 158 170 177 183 188 194 204 209 210 207 202 196 199 206 208 203 182 155 159 172 187 203 229 227 207 208 215 215 211 216 221 223 227 197 22 15 36 41 32 13 13 16 18 23 24 120 128 139 153 164 171 177 182 185 195 204 209 211 208 208 207 212 211 201 176 157 155 168 183 198 225 230 207 206 216 218 218 220 220 219 227 176 11 18 29 44 30 11 14 19 25 22 24 110 123 134 147 152 163 172 173 178 185 194 199 207 210 210 214 217 214 195 169 151 150 170 190 201 224 233 211 202 208 216 221 223 220 213 226 144 2 21 26 40 27 12 19 18 19 24 21 107 118 133 139 142 150 158 167 175 183 191 201 207 212 213 214 213 207 189 156 138 152 174 191 204 224 236 219 205 202 212 217 221 221 217 225 105 1 22 29 38 19 15 11 13 13 16 23 106 118 129 134 136 143 151 161 168 177 186 199 204 208 213 214 207 198 178 137 132 155 171 189 201 220 236 231 212 202 203 208 214 216 214 218 72 9 25 31 37 15 7 5 7 12 11 35 103 114 126 131 136 143 148 154 159 167 179 188 194 201 203 206 203 189 163 120 149 171 177 187 202 214 230 237 222 207 196 203 208 208 208 200 46 14 28 37 33 15 5 1 5 3 22 23 103 111 124 132 132 139 150 155 161 164 170 178 187 192 193 194 191 180 144 113 154 158 178 181 197 209 221 228 224 210 192 194 200 202 206 178 25 19 32 40 19 4 2 3 1 11 23 6 105 112 125 129 131 137 143 156 157 162 166 168 175 186 188 188 181 175 138 108 144 138 149 145 159 189 198 208 212 198 186 191 195 196 208 153 14 25 42 67 104 82 28 4 1 24 11 7 109 112 125 131 132 137 138 150 157 161 165 169 173 179 185 182 177 174 146 105 132 133 108 116 127 138 162 175 182 189 190 193 195 195 210 127 10 28 90 167 216 196 151 81 46 18 2 17 116 117 121 128 129 130 137 140 150 163 164 166 171 174 173 178 180 180 156 113 103 99 84 96 115 130 128 129 181 213 201 194 193 197 210 93 6 58 140 209 212 190 180 160 126 81 42 6 119 118 116 117 122 128 136 137 144 161 162 164 166 165 174 184 191 187 172 135 115 106 106 113 114 125 130 164 221 217 206 198 192 199 201 59 18 99 170 209 204 206 215 219 220 219 212 142 117 114 112 117 123 127 129 138 147 159 162 163 165 163 174 183 192 194 184 159 137 126 123 133 128 131 163 200 219 213 210 204 193 201 174 27 54 125 211 227 230 233 235 235 238 237 237 241 116 118 118 124 123 124 126 137 148 155 155 160 164 164 173 183 190 189 181 172 158 144 136 146 151 153 186 211 217 207 205 205 190 201 131 29 107 179 220 219 222 223 218 216 219 218 220 218 110 121 122 124 125 124 128 134 145 148 153 162 162 164 173 184 186 187 179 173 168 164 168 181 193 197 215 222 219 200 191 197 183 196 100 48 147 219 214 215 216 215 217 220 226 230 228 225 108 117 123 120 121 123 130 137 141 145 156 162 161 160 168 176 177 177 178 176 179 176 161 155 160 176 150 136 177 180 160 179 190 180 61 97 201 208 210 217 218 221 226 228 228 228 225 226 104 111 116 118 121 123 129 136 139 147 153 156 157 158 166 165 160 150 151 143 116 98 91 86 83 89 81 79 80 80 115 169 202 122 75 184 202 202 210 215 208 211 214 212 208 208 212 217 97 104 111 119 121 121 124 130 137 142 148 156 155 153 154 121 80 73 66 76 76 73 81 91 98 133 160 164 158 146 136 171 176 98 158 192 201 210 213 210 204 210 209 207 210 216 223 227 85 99 108 116 117 117 119 125 130 136 145 151 150 148 145 124 106 108 110 114 140 161 179 185 191 210 201 178 194 200 162 163 146 150 188 201 210 216 217 203 203 211 219 218 222 224 225 225 68 88 100 114 117 116 116 119 127 129 138 145 145 146 157 166 170 166 155 144 136 143 154 165 163 156 160 166 182 173 151 160 167 193 203 208 213 215 216 213 214 217 222 223 222 221 215 207 29 65 88 101 114 117 114 115 121 123 129 132 135 140 146 143 144 142 142 140 138 135 125 123 116 109 127 151 159 155 158 168 190 202 207 212 217 218 220 225 225 224 221 220 213 206 196 186 14 22 59 83 98 105 107 112 116 116 117 120 127 132 129 125 124 120 120 123 127 124 113 103 104 108 125 148 156 154 156 186 203 209 214 218 221 222 221 223 223 220 214 207 199 161 126 102 18 14 16 42 69 84 93 100 106 110 110 115 117 118 118 119 117 116 118 118 119 115 117 135 143 148 166 181 179 152 177 203 212 217 219 223 227 225 224 221 219 213 202 201 162 55 64 95 15 15 13 12 25 47 67 78 85 92 97 102 105 111 118 121 122 128 134 142 152 158 162 175 190 192 196 197 177 175 206 214 220 223 224 226 227 226 225 221 215 207 196 150 97 123 171 192 16 14 13 12 10 13 27 45 56 61 71 82 94 108 123 129 137 142 154 167 180 189 190 185 191 198 198 191 183 203 217 221 224 224 225 224 224 225 224 217 209 195 151 99 146 189 199 201,PrivateTest\\n']\n",
      "number of instances:  35888\n"
     ]
    }
   ],
   "source": [
    "with open(\"D:/Arbeit/semester5/comppx18/Projekt/Datasets/KaggleEmotion/fer2013/fer2013.csv\") as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "    lines = np.array(content)\n",
    "\n",
    "    num_of_instances = lines.size\n",
    "print(\"number of instances: \",num_of_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = [], [], [], []\n",
    "for i in range(1,num_of_instances):\n",
    "    try:\n",
    "        emotion, img, usage = lines[i].split(\",\")\n",
    "\n",
    "        val = img.split(\" \")\n",
    "        pixels = np.array(val, 'float32')\n",
    "        emotion = keras.utils.to_categorical(emotion, 7)\n",
    "        if 'Training' in usage:\n",
    "            y_train.append(emotion)\n",
    "            x_train.append(pixels)\n",
    "        elif 'PublicTest' in usage:\n",
    "            y_test.append(emotion)\n",
    "            x_test.append(pixels)\n",
    "    except:\n",
    "        print(\"\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "x_train = np.array(x_train)\n",
    "y_test = np.array(y_test)\n",
    "x_test = np.array(x_test)\n",
    "x_train = x_train.reshape((len(x_train),48,48)+(1,))\n",
    "x_test = x_test.reshape((len(x_test),48,48)+(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "#np.concatenate((np.ones((len(x_train),1), dtype=np.int), x_train.reshape(len(x_train),1)), axis=1)\n",
    "#print(x_train.shape)\n",
    "#x_train = np.insert(x_train, 0, values=30, axis=1) \n",
    "#print(x_train)\n",
    "#print(x_train.shape)\n",
    "print(x_train.shape)\n",
    "#x_train = x_train.reshape((len(x_train), len(x_train[0])))\n",
    "#x_train = x_train.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    " \n",
    "#1st convolution layer\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))\n",
    " \n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    " \n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    " \n",
    "model.add(layers.Flatten())\n",
    " \n",
    "#fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 32/128 [======>.......................] - ETA: 33:40 - loss: 13.5400 - acc: 0.1343"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-259-27d9d4dd33a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m )\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "batch_size = 128\n",
    "gen = ImageDataGenerator()\n",
    "train_generator = gen.flow(x_train, y_train, batch_size=batch_size)\n",
    " \n",
    "model.compile(loss='categorical_crossentropy'\n",
    ", optimizer=keras.optimizers.Adam()\n",
    ", metrics=['accuracy']\n",
    ")\n",
    "model.fit_generator(train_generator, steps_per_epoch=batch_size, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"faceEmotion1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Train loss:', train_score[0])\n",
    "print('Train accuracy:', 100*train_score[1])\n",
    " \n",
    "test_score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', test_score[0])\n",
    "print('Test accuracy:', 100*test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.metrics import classification_report, confusion_matrix\n",
    "pred_list = []; actual_list = []\n",
    "for i in predictions:\n",
    "pred_list.append(np.argmax(i))\n",
    "for i in y_test:\n",
    "actual_list.append(np.argmax(i))\n",
    "confusion_matrix(actual_list, pred_list)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_analysis(emotions):\n",
    "    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "    y_pos = np.arange(len(objects))\n",
    "\n",
    "    plt.bar(y_pos, emotions, align='center', alpha=0.5)\n",
    "    plt.xticks(y_pos, objects)\n",
    "    plt.ylabel('percentage')\n",
    "    plt.title('emotion')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(\"C:/Users/mike/Pictures/Camera Roll/pablo.png\", grayscale=True, target_size=(48, 48))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "x /= 255\n",
    "custom = model.predict(x)\n",
    "emotion_analysis(custom[0])\n",
    "x = np.array(x, 'float32')\n",
    "x = x.reshape([48, 48]);\n",
    "plt.gray()\n",
    "plt.imshow(x)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
